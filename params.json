{"name":"Time-domain acoustic rake receiver","tagline":"Software design and analysis tools for the acoustic rake receiver, a microphone beamformer that uses echoes to improve the noise and interference suppression. Python code to reproduce all the results from Raking Echoes in the Time Domain by Robin Scheibler, Ivan Dokmanic, and Martin Vetterli.","body":"Time-Domain Acoustic Rake Receiver\r\n==================================\r\n\r\nThis repository contains all the code to reproduce the results of the paper\r\n[*Raking Echoes in the Time Domain*](https://infoscience.epfl.ch/record/202223).\r\n\r\nUsing the simple python room acoustics framework created for the \r\n[Acoustic Rake Receiver](https://github.com/LCAV/AcousticRakeReceiver),\r\nwe demonstrate two time domain beamformer designs that use echoes constructively\r\nto improve the signal to interference and noise ratio.\r\nThese designs are explained in details in the paper *Raking Echoes in the Time Domain*.\r\nAll the figures of the paper can be recreated by calling\r\nsimple scripts leveraging this framework. In addition to the results of\r\nthe paper, we include spectrograms and samples of speech samples.\r\nWe strongly hope that this code will be useful beyond the scope of this paper\r\nand plan to develop it into a standalone python package in the future.\r\n\r\nWe are available for any question or request relating to either the code\r\nor the theory behind it. Just ask!\r\n\r\n\r\nAbstract\r\n--------\r\n\r\nThe geometry of room acoustics is such that the reverberant signal can be seen\r\nas a single signal emitted from multiple locations. In analogy with the rake\r\nreceiver from wireless communications, we propose several beamforming\r\nstrategies that exploit, rather than suppress, this extra temporal diversity.\r\nUnlike earlier work in the frequency domain, time domain designs allow to\r\ncontrol important timing parameters. Particularly important is the ability to\r\ncontrol perceptually relevant parameters such as the amount of early echoes or\r\nthe length of the beamformer response.  \r\n\r\nRelying on the knowledge of the position of sources, we derive several optimal\r\nbeamformers. Leveraging perceptual cues, we stray from distortionless design\r\nand improve interference and noise reduction without degrading the perceptual\r\nquality. The designs are validated through simulation. Using early echoes is\r\nshown to strictly improve the signal to interference and noise ratio. Code and\r\nspeech samples are available online in this repository.\r\n\r\n\r\nAuthors\r\n-------\r\n\r\nRobin Scheibler, Ivan Dokmanić, and Martin Vetterli are with \r\nLaboratory for Audiovisual Communications ([LCAV](http://lcav.epfl.ch)) at \r\n[EPFL](http://www.epfl.ch).\r\n\r\n<img src=\"http://lcav.epfl.ch/files/content/sites/lcav/files/images/Home/LCAV_anim_200.gif\">\r\n\r\n#### Contact\r\n\r\n[Robin Scheibler](mailto:robin[dot]scheibler[at]epfl[dot]ch) <br>\r\nEPFL-IC-LCAV <br>\r\nBC Building <br>\r\nStation 14 <br>\r\n1015 Lausanne\r\n\r\n\r\nRecreate the figures and sound samples\r\n--------------------------------------\r\n\r\nIn a UNIX terminal, run the following script.\r\n\r\n    ./make_all_figures.sh\r\n\r\nAlternatively, type in the following commands in an ipython shell.\r\n\r\n    run figure_beampatterns.py\r\n    run figure_SINR_sim.py\r\n    run figure_SINR_plot.py\r\n\r\nThe figures and sound samples generated are collected in `figures` and\r\n`output_samples`, respectively.\r\n\r\nThe SINR simulation can be very long. For that reason, we split\r\nthe simulation loop and the plotting routine into two files.\r\nWe recommend to first modify the value of the `loops` variable\r\nin `figure_SINR_sim.py` to 10 and time the simulation to have an\r\nestimate of the total time required to run the simulatioin.\r\nThe output of the simulation is saved in `data/SINR_data.npy`.\r\nThe data can be plotted using `figure_SINR_plot.py`.\r\n\r\n\r\nSimulation Data\r\n---------------\r\n\r\nThe simulation data from the paper is available in `data/SINR_data_Lg30ms_d20ms_20141008.npy`\r\nand can be processed with `figure_SINR_plot.py`.\r\n\r\n\r\nSound Samples and Spectrograms\r\n------------------------------\r\n\r\nWhile it was omitted in the paper for space reasons, we provide\r\nhere simulation results for speech samples.\r\n\r\n* [sample1](https://raw.githubusercontent.com/LCAV/TimeDomainAcousticRakeReceiver/master/output_samples/input.wav) \r\n  Simulated microphone input signal.\r\n* [sample2](https://raw.githubusercontent.com/LCAV/TimeDomainAcousticRakeReceiver/master/output_samples/output_DirectMVDR.wav) \r\n  Output of MVDR using the direct sound only.\r\n* [sample3](https://raw.githubusercontent.com/LCAV/TimeDomainAcousticRakeReceiver/master/output_samples/output_RakeMVDR.wav) \r\n  Output of Rake MVDR using the direct sound and 1st order echoes.\r\n* [sample4](https://raw.githubusercontent.com/LCAV/TimeDomainAcousticRakeReceiver/master/output_samples/output_DirectPerceptual.wav) \r\n  Output of Perceptual beamformer using the direct sound only.\r\n* [sample5](https://raw.githubusercontent.com/LCAV/TimeDomainAcousticRakeReceiver/master/output_samples/output_RakePerceptual.wav) \r\n  Output of Rake Perceptual using the direct sound and 1st order echoes.\r\n\r\nThe spectrogram of all samples as well as the desired sound are provided.\r\n\r\n<img src=\"https://raw.githubusercontent.com/LCAV/TimeDomainAcousticRakeReceiver/master/figures/spectrograms.png\">\r\n\r\nThe samples and the spectrograms are created by the script `figure_spectrogam_and_samples.py`.\r\n\r\n\r\nExtra Scripts\r\n-------------\r\n\r\nWe also include extra scripts that let us play with the different beamformers.\r\nThe script names should be self-explanatory.\r\n\r\n    RakeLstSqFromFD.py\r\n    RakeMVDR.py\r\n    RakeMaxSINR.py\r\n    RakeMaxUDR.py\r\n    RakeOF.py\r\n    RakePerceptual.py\r\n\r\n\r\nDependencies\r\n------------\r\n\r\n* A working distribution of [Python 2.7](https://www.python.org/downloads/).\r\n* The code relies heavily on [Numpy](http://www.numpy.org/),\r\n  [Scipy](http://www.scipy.org/), and [matplotlib](http://matplotlib.org).\r\n* We use the distribution [anaconda](https://store.continuum.io/cshop/anaconda/) to simplify the setup\r\n  of the environment.\r\n* Computations are very heavy and we use the\r\n  [MKL](https://store.continuum.io/cshop/mkl-optimizations/) extension of\r\n  Anaconda to speed things up. There is a [free license](https://store.continuum.io/cshop/academicanaconda) for academics.\r\n\r\n\r\nSystems Tested\r\n--------------\r\n\r\n###Linux\r\n\r\n| Machine | IBM System X iDataPlex dx360 M3 |\r\n|---------|---------------------------------|\r\n| System  | Ubuntu 12.04.5                  |\r\n| CPU     | 2x X5675                        |\r\n| RAM     | 96 GB                           |\r\n\r\n    System Info:\r\n    Linux 3.11.0-26-generic #45~precise1-Ubuntu SMP Tue Jul 15 04:02:35 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n    Python Info:\r\n    Python 2.7.8 :: Anaconda 2.0.1 (64-bit)\r\n\r\n    Python Packages Info:\r\n    accelerate                1.7.0               np19py27_p0  \r\n    anaconda                  2.0.1                np18py27_0  \r\n    ipython                   2.1.0                    py27_2  \r\n    ipython-notebook          2.1.0                    py27_0  \r\n    ipython-qtconsole         2.1.0                    py27_0  \r\n    matplotlib                1.3.1                np18py27_1  \r\n    mkl                       11.1                np19py27_p3  \r\n    mkl-rt                    11.1                         p0  \r\n    mkl-service               1.0.0                   py27_p1  \r\n    mklfft                    1.0                 np19py27_p0  \r\n    numpy                     1.9.0                   py27_p0  [mkl]\r\n    scipy                     0.14.0              np19py27_p0  [mkl]\r\n\r\n###OS X\r\n\r\n| Machine | MacBook Pro Retina 15-inch, Early 2013 |\r\n|---------|----------------------------------------|\r\n| System  | OS X Maverick 10.9.4                   |\r\n| CPU     | Intel Core i7                          |\r\n| RAM     | 16 GB                                  |\r\n\r\n    System Info:\r\n    Darwin 13.3.0 Darwin Kernel Version 13.3.0: Tue Jun  3 21:27:35 PDT 2014; root:xnu-2422.110.17~1/RELEASE_X86_64 x86_64\r\n\r\n    Python Info:\r\n    Python 2.7.8 :: Anaconda 2.0.1 (x86_64)\r\n\r\n    Python Packages Info:\r\n    accelerate                1.7.0               np19py27_p0  \r\n    anaconda                  2.0.1                np18py27_0  \r\n    ipython                   2.1.0                    py27_2  \r\n    ipython-notebook          2.1.0                    py27_0  \r\n    ipython-qtconsole         2.1.0                    py27_0  \r\n    matplotlib                1.3.1                np18py27_1  \r\n    mkl                       11.1                np19py27_p3  \r\n    mkl-rt                    11.1                         p0  \r\n    mkl-service               1.0.0                   py27_p1  \r\n    mklfft                    1.0                 np19py27_p0  \r\n    numpy                     1.9.0                   py27_p0  [mkl]\r\n    scipy                     0.14.0              np19py27_p0  [mkl]\r\n\r\n\r\nLicense\r\n-------\r\n\r\nCopyright (c) 2014, Robin Scheibler, Ivan Dokmanić, Martin Vetterli\r\n\r\nThis code is free to reuse for non-commercial purpose such as academic or\r\neducational. For any other use, please contact the authors.\r\n\r\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Time Domain Acoustic Rake Receiver</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://lcav.epfl.ch\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Robin Scheibler, Ivan Dokmanić, Martin Vetterli</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.<br />Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/LCAV/AcousticRakeReceiver\" rel=\"dct:source\">https://github.com/LCAV/AcousticRakeReceiver</a>.\r\n\r\n","google":"UA-58615911-2","note":"Don't delete this file! It's used internally to help with page regeneration."}